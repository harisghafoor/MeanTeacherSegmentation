{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eloise-em/miniconda3/envs/ssl/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/eloise-em/miniconda3/envs/ssl/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <5AA8DD3D-A2CC-31CA-8060-88B4E9C18B09> /Users/eloise-em/miniconda3/envs/ssl/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <CDAC6E34-8608-3E70-8B2F-32BCD38E90FB> /Users/eloise-em/miniconda3/envs/ssl/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import OxfordIIITPet\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "\n",
    "# from segmentation_models_pytorch.losses import SoftBCEWithLogitsLoss\n",
    "# from torchmetrics.classification import BinaryJaccardIndex\n",
    "# from torchmetrics import Dice\n",
    "import pickle\n",
    "\n",
    "from dataset import LabeledUnlabeledPetDataset\n",
    "from data import TwoStreamBatchSampler, SingleStreamBaselineSampler\n",
    "from utils import accuracy_fn, update_ema, softmax_mse_loss\n",
    "from ramp_up import get_current_consistency_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: mps\n"
     ]
    }
   ],
   "source": [
    "# Check if the GPU is available\n",
    "DEVICE = (\n",
    "    torch.device(\"cuda\")\n",
    "    if torch.cuda.is_available()\n",
    "    else (\n",
    "        torch.device(\"mps\")\n",
    "        if torch.backends.mps.is_available()\n",
    "        else torch.device(\"cpu\")\n",
    "    )\n",
    ")\n",
    "print(f\"Selected device: {DEVICE}\")\n",
    "\n",
    "NO_LABEL = -1\n",
    "CUDA_LAUNCH_BLOCKING = 1\n",
    "global_step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data...\n",
      "Downloading https://thor.robots.ox.ac.uk/datasets/pets/images.tar.gz to data/oxford-iiit-pet/images.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 791918971/791918971 [15:40<00:00, 842364.72it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/oxford-iiit-pet/images.tar.gz to data/oxford-iiit-pet\n",
      "Downloading https://thor.robots.ox.ac.uk/datasets/pets/annotations.tar.gz to data/oxford-iiit-pet/annotations.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19173078/19173078 [00:28<00:00, 674618.09it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/oxford-iiit-pet/annotations.tar.gz to data/oxford-iiit-pet\n"
     ]
    }
   ],
   "source": [
    "global global_step\n",
    "\n",
    "print(\"==> Preparing data...\")\n",
    "\n",
    "# Initialize the data loading parameters\n",
    "data_dir = \"data/oxford-iiit-pet\"\n",
    "batch_size = 64\n",
    "labeled_batch_size = 32\n",
    "workers = 4\n",
    "unlabeled_ratio = 0.95\n",
    "\n",
    "# Download the dataset\n",
    "dataset = OxfordIIITPet(\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    target_types=\"segmentation\",\n",
    ")\n",
    "\n",
    "# Load the training data from custom dataset\n",
    "train_data = LabeledUnlabeledPetDataset(\n",
    "    data_dir, train=True, labeled=False, unlabeled_ratio=unlabeled_ratio\n",
    ")\n",
    "# Create the batch sampler\n",
    "batch_sampler = TwoStreamBatchSampler(\n",
    "    train_data.unlabeled_idxs, train_data.labeled_idxs, batch_size, labeled_batch_size\n",
    ")\n",
    "# Create the data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_sampler=batch_sampler, num_workers=workers, pin_memory=True\n",
    ")\n",
    "\n",
    "test_data = LabeledUnlabeledPetDataset(data_dir, train=False, labeled=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=False, num_workers=workers * 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "# Include the two batch sampler in the exisitng pipeline\n",
    "# test the performance after and before for all those experiments\n",
    "# Create a single script for it\n",
    "# Create mean teacher network with two batch sampler and test the performance\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
